{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5656458, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Indicators.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>IndicatorName</th>\n",
       "      <th>IndicatorCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Adolescent fertility rate (births per 1,000 wo...</td>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>1960</td>\n",
       "      <td>1.335609e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Age dependency ratio (% of working-age populat...</td>\n",
       "      <td>SP.POP.DPND</td>\n",
       "      <td>1960</td>\n",
       "      <td>8.779760e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Age dependency ratio, old (% of working-age po...</td>\n",
       "      <td>SP.POP.DPND.OL</td>\n",
       "      <td>1960</td>\n",
       "      <td>6.634579e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Age dependency ratio, young (% of working-age ...</td>\n",
       "      <td>SP.POP.DPND.YG</td>\n",
       "      <td>1960</td>\n",
       "      <td>8.102333e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Arms exports (SIPRI trend indicator values)</td>\n",
       "      <td>MS.MIL.XPRT.KD</td>\n",
       "      <td>1960</td>\n",
       "      <td>3.000000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CountryName CountryCode                                      IndicatorName  \\\n",
       "0  Arab World         ARB  Adolescent fertility rate (births per 1,000 wo...   \n",
       "1  Arab World         ARB  Age dependency ratio (% of working-age populat...   \n",
       "2  Arab World         ARB  Age dependency ratio, old (% of working-age po...   \n",
       "3  Arab World         ARB  Age dependency ratio, young (% of working-age ...   \n",
       "4  Arab World         ARB        Arms exports (SIPRI trend indicator values)   \n",
       "\n",
       "    IndicatorCode  Year         Value  \n",
       "0     SP.ADO.TFRT  1960  1.335609e+02  \n",
       "1     SP.POP.DPND  1960  8.779760e+01  \n",
       "2  SP.POP.DPND.OL  1960  6.634579e+00  \n",
       "3  SP.POP.DPND.YG  1960  8.102333e+01  \n",
       "4  MS.MIL.XPRT.KD  1960  3.000000e+06  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(data):\n",
    "    data=data[(data['Year'] >= 2000) & (data['Year'] < 2015) ]\n",
    "    for i in data.columns:\n",
    "        if data.isna().sum()[i]/len(data) >=0.8:\n",
    "            data=data.drop(columns=[i])\n",
    "\n",
    "    rel_columns= []\n",
    "    rel_columns_7=[]\n",
    "    unique_name = data['IndicatorName'].unique()\n",
    "    for i in range(len(unique_name)):\n",
    "        #print(unique_name[i])\n",
    "        indicator = data[data['IndicatorName'] == unique_name[i]]\n",
    "        indicator.rename(columns={\"Value\": unique_name[i]}, inplace = True)\n",
    "        indicator=indicator.drop(columns=['IndicatorCode', 'IndicatorName', 'CountryName'])\n",
    "        merged = pd.merge(target, indicator)\n",
    "        corr=merged.corr()\n",
    "        if corr['Value'][unique_name[i]] > 0.8 or corr['Value'][unique_name[i]] < -0.8:\n",
    "            rel_columns.append(unique_name[i])\n",
    "        if corr['Value'][unique_name[i]] > 0.7 or corr['Value'][unique_name[i]] < -0.7:\n",
    "            rel_columns_7.append(unique_name[i])\n",
    "    return rel_columns, rel_columns_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일단 이렇게 되는데, 나중에 주석 풀고 하는게 나을듯\n",
    "#rel_columns_8,rel_columns_7=corr(data2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서부터 관련도 높은 feature 뽑는 것\n",
    "target_id = 'Adolescent fertility rate (births per 1,000 women ages 15-19)';\n",
    "\n",
    "target = data[data['IndicatorName']==target_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_columns_8 = ['Adolescent fertility rate (births per 1,000 women ages 15-19)',\n",
    " 'Birth rate, crude (per 1,000 people)',\n",
    " 'Net enrolment rate, secondary, both sexes (%)',\n",
    " 'Net enrolment rate, secondary, female (%)',\n",
    " 'Net enrolment rate, secondary, male (%)',\n",
    " 'Teenage mothers (% of women ages 15-19 who have had children or are currently pregnant)',\n",
    " 'Mortality rate, under-5, female (per 1,000 live births)',\n",
    " 'Mortality rate, under-5, male (per 1,000 live births)',\n",
    " 'Prevalence of anemia among children (% of children under 5)',\n",
    " 'Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total)',\n",
    " 'Cause of death, by non-communicable diseases (% of total)',\n",
    " 'Survey mean consumption or income per capita, bottom 40% of population (2005 PPP $ per day)',\n",
    " 'Survey mean consumption or income per capita, total population (2005 PPP $ per day)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_columns_7 = ['Adolescent fertility rate (births per 1,000 women ages 15-19)',\n",
    " 'Age dependency ratio (% of working-age population)',\n",
    " 'Age dependency ratio, young (% of working-age population)',\n",
    " 'Birth rate, crude (per 1,000 people)',\n",
    " 'Fertility rate, total (births per woman)',\n",
    " 'Life expectancy at birth, female (years)',\n",
    " 'Life expectancy at birth, male (years)',\n",
    " 'Life expectancy at birth, total (years)',\n",
    " 'Mortality rate, adult, female (per 1,000 female adults)',\n",
    " 'Mortality rate, infant (per 1,000 live births)',\n",
    " 'Mortality rate, under-5 (per 1,000)',\n",
    " 'Population, ages 0-14 (% of total)',\n",
    " 'Population, ages 15-64 (% of total)',\n",
    " 'Survival to age 65, female (% of cohort)',\n",
    " 'Survival to age 65, male (% of cohort)',\n",
    " 'Adjusted net enrolment rate, primary, both sexes (%)',\n",
    " 'Adjusted net enrolment rate, primary, female (%)',\n",
    " 'Gross enrolment ratio, secondary, both sexes (%)',\n",
    " 'Gross enrolment ratio, secondary, female (%)',\n",
    " 'Gross enrolment ratio, secondary, male (%)',\n",
    " 'Lower secondary completion rate, both sexes (%)',\n",
    " 'Net enrolment rate, secondary, both sexes (%)',\n",
    " 'Net enrolment rate, secondary, female (%)',\n",
    " 'Net enrolment rate, secondary, male (%)',\n",
    " 'Primary completion rate, both sexes (%)',\n",
    " 'Primary completion rate, female (%)',\n",
    " 'Survival rate to the last grade of primary education, both sexes (%)',\n",
    " 'Lower secondary completion rate, female (%)',\n",
    " 'Lower secondary completion rate, male (%)',\n",
    " 'Survival rate to the last grade of primary education, female (%)',\n",
    " 'Survival rate to the last grade of primary education, male (%)',\n",
    " 'Survival rate to Grade 5 of primary education, female (%)',\n",
    " 'Youth literacy rate, population 15-24 years, both sexes (%)',\n",
    " 'Youth literacy rate, population 15-24 years, male (%)',\n",
    " 'Teenage mothers (% of women ages 15-19 who have had children or are currently pregnant)',\n",
    " 'Wanted fertility rate (births per woman)',\n",
    " 'Access to electricity (% of population)',\n",
    " 'Access to electricity, rural (% of rural population)',\n",
    " 'Improved sanitation facilities (% of population with access)',\n",
    " 'Improved sanitation facilities, rural (% of rural population with access)',\n",
    " 'Improved sanitation facilities, urban (% of urban population with access)',\n",
    " 'Improved water source (% of population with access)',\n",
    " 'Improved water source, rural (% of rural population with access)',\n",
    " 'Lifetime risk of maternal death (%)',\n",
    " 'Maternal mortality ratio (modeled estimate, per 100,000 live births)',\n",
    " 'Mortality rate, infant, female (per 1,000 live births)',\n",
    " 'Mortality rate, infant, male (per 1,000 live births)',\n",
    " 'Mortality rate, neonatal (per 1,000 live births)',\n",
    " 'Mortality rate, under-5, female (per 1,000 live births)',\n",
    " 'Mortality rate, under-5, male (per 1,000 live births)',\n",
    " 'Prevalence of anemia among children (% of children under 5)',\n",
    " 'Prevalence of anemia among pregnant women (%)',\n",
    " 'Renewable energy consumption (% of total final energy consumption)',\n",
    " 'Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total)',\n",
    " 'Cause of death, by non-communicable diseases (% of total)',\n",
    " 'Survey mean consumption or income per capita, bottom 40% of population (2005 PPP $ per day)',\n",
    " 'Survey mean consumption or income per capita, total population (2005 PPP $ per day)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당하는 indicator해서 그 데이터 프레임 사용하기 편하게 바꿔주는거 \n",
    "def transformDf(data, ind):\n",
    "    data2000=data[(data['Year'] >= 2000) & (data['Year'] < 2015) ]\n",
    "    col8 = data2000[(data2000['IndicatorName'].isin(ind))]\n",
    "    col8=col8.reset_index(drop=True)\n",
    "    name_list = list()\n",
    "\n",
    "    for i in col8.index:\n",
    "        name_list.append( col8.loc[i,'CountryName'] + \"_\" + str(col8.loc[i,'Year']))\n",
    "    col8[\"name\"] = name_list\n",
    "    \n",
    "    col8=col8.pivot_table(values=\"Value\",index=\"name\",columns=[\"IndicatorName\"] )\n",
    "\n",
    "    col8=col8.dropna(subset=[target_id])\n",
    "    return col8\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_grade(merged, k):\n",
    "    min_value = min(merged[target_id])\n",
    "    max_value = max(merged[target_id])\n",
    "    value=(max_value-min_value)/k\n",
    "    for i in range(k):\n",
    "        for j in merged.index:\n",
    "            if merged.loc[j, target_id] >=min_value + value*i and merged.loc[j, target_id] <= min_value + value*(i+1):\n",
    "                merged.loc[j, 'grade'] = i\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른 missing value추가하는거 넣어야될듯\n",
    "1. 아예 드랍\n",
    "2. missing value을 채우고 난 뒤, 그래도 못 채우면 드랍\n",
    "    예시)- 한개 column 이 na 일 때 가정, indicator=[a,b,c]\n",
    "    \n",
    "        1) if a[한국] is null\n",
    "            b[한국] & c[한국] 비슷한 다른 나라 참조 해서 a[한국]=a[다른나라]\n",
    "            이렇게 알고리즘 짜고 그래도 못할시에 na로 일단 남겨 놓고, 마지막에 검사해서 드랍\n",
    "            \n",
    "        2) 비슷한 연도이니까, 거의 안그럴 거 같은데 2001년은 null이고 2000은 null 이 아니면 2000년도꺼 그냥 쓴다던지,,, \n",
    "        그 regression? 그런거 써서 processing 에서도 그 predict 써서 채워넣돈지\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingMissing(df):\n",
    "    \n",
    "    #전체 개수랑 null 값이 비슷 하게 나오는 경우에는 그냥 아예 그 컬럼을 안쓰는게 나을 거 가음\n",
    "    for i in df.columns:\n",
    "        if df.isna().sum()[i]/len(df) >=0.7:\n",
    "\n",
    "            df=df.drop(columns=[i])\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=transformDf(data,rel_columns_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=preprocessingMissing(df)\n",
    "#df1[df_pre.isnull()['Net enrolment rate, secondary, both sexes (%)']==True]\n",
    "\n",
    "l=df1.index.values\n",
    "for i in range(len(df1)):\n",
    "    df1.loc[l[i],'code']=l[i].split(\"_\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Birth rate, crude (per 1,000 people)',\n",
       " 'Net enrolment rate, secondary, both sexes (%)',\n",
       " 'Net enrolment rate, secondary, female (%)',\n",
       " 'Net enrolment rate, secondary, male (%)',\n",
       " 'Prevalence of anemia among children (% of children under 5)']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanColumn=list()\n",
    "for j in df1.columns:\n",
    "    if df1.isna().sum()[j]>0:\n",
    "        nanColumn.append(j)\n",
    "        \n",
    "nanColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "3\n",
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "10\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "15\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "4\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "10\n",
      "3\n",
      "1\n",
      "6\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "7\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "10\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "13\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "8\n",
      "10\n",
      "10\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "10\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "15\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "3\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "15\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "10\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "10\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "7\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "15\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "10\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "3\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "15\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "3\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "10\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "unique_country=df1.code.unique()\n",
    "for i in range(len(unique_country)):\n",
    "    dfC=df1[df1.code==unique_country[i]]\n",
    "    for j in nanColumn:\n",
    "        if dfC.loc[:,j].isna().sum():\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleansing dataset\n",
    "def robust(X):\n",
    "    # cleansing missing data\n",
    "    X.dropna(axis=0, thresh=1, inplace=True)\n",
    "    # cleansing outliers\n",
    "    robust = preprocessing.RobustScaler().fit(X)\n",
    "\n",
    "    X_robust = robust.transform(X)\n",
    "    X_robust = pd.DataFrame(X, columns=X.columns, index=list(X.index.values))\n",
    "    return X_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data (MinMaxScaler)\n",
    "def minmax(X):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    fit = scaler.fit(X)\n",
    "\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=list(X.index.values))\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data (MinMaxScaler)\n",
    "def standard(X):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    fit = scaler.fit(X)\n",
    "\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=list(X.index.values))\n",
    "    return X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillnaX(X):\n",
    "    for i in X.columns:\n",
    "        df[i] = df[i].fillna(df[i].mean())\n",
    "    return X                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#나중에 dbscan이나 EM 도 한파일에 있어야되서 함수 명 바꿧어\n",
    "def runKMeans(df, k,max_iter, n_init):\n",
    "    \n",
    "    kmeans= KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=max_iter, \n",
    "               n_clusters=k, n_init=n_init, n_jobs=1, precompute_distances='auto', \n",
    "               random_state=None, tol=0.0001, verbose=0)\n",
    "    df=make_grade(df,k)\n",
    "    df=preprocessingMissing(df)\n",
    "    \n",
    "    X= df.drop(['grade',target_id], 1)\n",
    "    #일단은 다 dropna 처리\n",
    "    X=X.dropna()\n",
    "    y=df['grade']\n",
    "\n",
    "    kmeans.fit(X)\n",
    "    predict=kmeans.predict(X)\n",
    "    return calcAccuracy(predict, X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcAccuracy(y_pred, x,y):\n",
    "    '''\n",
    "    print accuracy of prediction\n",
    "    '''\n",
    "    correct=0\n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        #predict_me= np.array(x[i].astype(float))\n",
    "        #predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "        #prediction = kmeans.predict(predict_me)\n",
    "        #여기서는 predict 값을 넘겨서 [i]로 해야돼\n",
    "        if y_pred[i] == y[i]:\n",
    "            correct += 1\n",
    "    print(correct/len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDBScan(df,eps, min_samples, metric):\n",
    "    \n",
    "    \n",
    "    X=df.drop(columns=['grade',target_id])\n",
    "    y=df['grade']\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    X=df.drop(columns=[target_id])\n",
    "    y=df[target_id]\n",
    "    \"\"\"\n",
    "    \n",
    "    X = robust(X)\n",
    "    X= fillnaX(X)\n",
    "\n",
    "    db = DBSCAN(eps = eps, min_samples = min_samples, metric= metric).fit(X) \n",
    "\n",
    "    cluster_labels = db.labels_\n",
    "    n_clusters = len(set(cluster_labels))\n",
    "    \n",
    "    return calcAccuracy(cluster_labels, X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=transformDf(data,rel_columns_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6411889596602972\n"
     ]
    }
   ],
   "source": [
    "runKMeans(df,2,800,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=[10, 20, 30, 40, 50 ]\n",
    "min_samples=[ 3, 5, 10, 15, 20, 30, 50, 100 ]\n",
    "dis_measure = ['euclidean', 'hamming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7477239353891336\n"
     ]
    }
   ],
   "source": [
    "runDBScan(df,10,3,'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "선택지\n",
    "1. rel_columns_8 or 7\n",
    "2. 몇개 미만이면 제외할지\n",
    "3. kmeans parameter\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
